# Стандарты проекта по Data Science

В этом документе описаны стандарты проекта MEPHI Coursework-Classical ML, основанные на отраслевых практиках и требованиях курса.

## Структура проекта
- `/data`: Сырые и обработанные наборы данных
- `/src`: Исходный код для обработки данных, моделирования и анализа
- `/notebooks`: Jupyter-ноутбуки для исследования и экспериментов
- `/reports`: Сгенерированные отчёты (EDA, оценка моделей и пр.)
- `/models`: Сохранённые обученные модели и объекты препроцессинга
- `/configs`: Конфигурационные файлы для препроцессинга, обучения и валидации
- `/figures`: Построенные визуализации и рисунки
- `/analysis`: Детальные результаты анализа (важность признаков, остатки и т.п.)
- `/logs`: Логи экспериментов и обучений

## Стандарты кода
- Весь Python-код должен соответствовать PEP8
- Использовать аннотации типов (type hints) для параметров функций и возвращаемых значений
- Модульность: чёткое разделение ответственности (загрузка данных, препроцессинг, моделирование, оценка)
- Документировать функции докстрингами (цель, параметры, возвращаемые значения)
- Использовать осмысленные имена переменных и функций

## Воспроизводимость
- Фиксировать все случайные состояния (numpy, sklearn, и т.д.) для воспроизводимости
- Использовать виртуальное окружение с зафиксированными версиями зависимостей (requirements.txt или pyproject.toml)
- Все гиперпараметры и пути к данным должны управляться конфигурационными файлами
- Логировать все результаты экспериментов вместе с параметрами и метриками

## Git-воркфлоу
- Использовать feature-ветки для разработки
- Сообщения коммитов должны быть ясными и информативными
- Делать небольшие, фокусированные коммиты, решающие одну задачу
- Шаблон имен веток: `feature/имя-задачи`, `fix/описание-ошибки`

## Обработка данных
- Никогда не коммитить сырые данные в репозиторий
- Документировать источники данных и трансформации
- Сохранять исходные данные и создавать отдельные обработанные версии
- Выявлять и корректно обрабатывать пропуски
- Проверять отсутствие утечки данных (data leakage) между признаками и целями

## Стандарты моделирования
- Делить данные на train/test до любой трансформации, чтобы избежать утечки
- Использовать кросс-валидацию для оценки моделей
- Для несбалансированных задач классификации применять методы (например, SMOTE) при необходимости
- Для классификации обеспечивать стратифицированные разбиения
- Использовать соответствующие метрики оценки:
  * Регрессия: RMSE, MAE, R2
  * Классификация: ROC-AUC, PR-AUC, F1 (macro), accuracy

## Трекинг экспериментов
- Логировать все эксперименты с параметрами и результатами
- Сохранять конфигурации моделей и обученные артефакты
- Документировать выводы и принятые решения в отчётах