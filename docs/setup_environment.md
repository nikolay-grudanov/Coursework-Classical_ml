# Подробная инструкция по настройке окружения и воспроизводимости пайплайнов

Цель этого руководства — шаг за шагом показать преподавателю, как воспроизвести весь pipeline проекта на чистой машине (Linux, macOS с zsh) и получить те же артефакты, которые были получены при разработке: обработанные данные, обученные модели, отчёты и логи.

Предположения
- Операционная система: Linux (Ubuntu/Debian) или macOS. В примерах используется zsh (по умолчанию в репозитории настроены команды для POSIX shell).
- Установлен conda (Miniconda или Anaconda) и доступна команда `conda`.
- Доступ к Интернету для установки зависимостей.

Краткий план шагов
1. Подготовить базу: конда, git, python
2. Создать и активировать conda-окружение
3. Установить зависимости (pip/conda)
4. Настроить `.env` (включая `DATA_PATH` при необходимости)
5. Быстрый smoke-test (`make check-config`)
6. Прогон пайплайна по шагам или полностью (`make all`)
7. Проверка артефактов и логов

1. Установка предварительных инструментов

Если conda ещё не установлена, установите Miniconda (пример для Linux):

```bash
# загрузить установщик
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda.sh
bash ~/miniconda.sh -b -p $HOME/miniconda
eval "$( $HOME/miniconda/bin/conda shell.zsh hook )"
conda init zsh
source ~/.zshrc
```

Проверьте версии:

```bash
conda --version
python --version
git --version
```

Рекомендуемые версии
- Python 3.10 или 3.11
- conda (miniconda3) свежей ветки

2. Создание conda-окружения (рекомендуется) и активация

Рекомендую создать отдельное окружение для проекта. Пример:

```bash
conda create -n mephi_ml python=3.10 -y
conda activate mephi_ml
```

Если вы используете системный Python или другую среду — важнее установить зависимости из `requirements.txt`.

3. Установка зависимостей

Проект содержит `requirements.txt` и `requirements.lock.txt`. Для воспроизводимости используйте `requirements.lock.txt` при возможности; обычно достаточно `requirements.txt`:

```bash
# в активированном окружении
pip install -r requirements.txt
```

Если нужен более контролируемый install через conda, можно установить ключевые пакеты через conda, затем pip для остального:

```bash
conda install -y numpy pandas scikit-learn joblib pyyaml
pip install -r requirements.txt
```

4. Настройка `.env` и `DATA_PATH`

Проект читает `.env` (если он есть) и использует переменные:

- `CONDA_PREFIX` — полный путь к conda-окружению (необязательно, если вы активируете окружение вручную)
- `CONDA_ENV_NAME` — имя окружения (альтернатива)
- `DATA_PATH` — путь к файлу с данными или директории (override)

Создайте копию примера и отредактируйте:

```bash
cp .env.example .env
${EDITOR:-nano} .env
```

В `.env` укажите, например:

```text
CONDA_ENV_NAME=mephi_ml
DATA_PATH=/home/teacher/data/drug_project/data.xlsx
```

Примечание о `DATA_PATH`: в конфиге проекта используется шаблон вида `${DATA_PATH:-data/data.xlsx}` — это значит, что если `DATA_PATH` не задан, будет использован путь `data/data.xlsx`. Рекомендую задавать `DATA_PATH` для явности.

5. Вспомогательные скрипты

В репозитории есть `scripts/activate_env.sh` — он читает `.env` и активирует окружение. Используйте его, если хотите:

```bash
source scripts/activate_env.sh
```

Если скрипт не подходит, активируйте окружение вручную:

```bash
conda activate mephi_ml
```

6. Быстрая проверка конфигурации (smoke-test)

Перед запуском полного pipeline выполните:

```bash
make check-config
```

Ожидаемый вывод — проверка путей из `configs/model_config.yaml`, которые должны резолвиться (OK) либо сообщать, какие файлы отсутствуют. Если `check-config` выдаёт ошибку — исправьте `DATA_PATH` или путь в конфигах.

7. Запуск пайплайна

Для пошагового запуска используйте make-цели:

```bash
make data       # обработка/предобработка данных
make features   # генерация дополнительных признаков
make train      # обучение моделей
make evaluate   # генерация отчётов и сравнений
make report     # финальная генерация отчётов (MD/PDF)
```

Или сразу весь pipeline:

```bash
make all
```

Примеры полезных команд для отладки:

```bash
# прогнать только обучение (быстрее для локальной проверки)
make train

# прогнать одну конкретную Python-часть (если нужно посмотреть ошибки)
conda run -n mephi_ml python src/main.py
```

8. Проверка результатов и логов

После выполнения `make all` проверьте следующие артефакты:

- `data/processed_data.csv` или путь, указанный в `DATA_PATH`
- `models/model_results.json` — JSON с метриками и best_params
- `reports/regression_comparison.md` и `reports/classification_comparison.md`
- `logs/pipeline.log` — лог выполнения пайплайна

Полезные команды:

```bash
ls -l models/
jq . models/model_results.json | less
sed -n '1,200p' logs/pipeline.log
```

9. Частые проблемы и советы по устранению

- FileNotFound / неправильный путь в конфиге: проверьте `DATA_PATH` в `.env` и значения в `configs/*.yaml`.
- Проблемы с зависимостями: используйте `pip install -r requirements.txt`. При ошибках попробуйте сначала установить ключевые библиотеки через conda (numpy, pandas, scikit-learn).
- ConvergenceWarning при ElasticNet: в коде по умолчанию уже увеличено `max_iter` и использован `StandardScaler`; если предупреждения сохраняются, можно:
  - увеличить `max_iter` до 100000 в `src/models/train_models.py`;
  - добавить большие значения в alpha-grid (например 100.0);
  - использовать `ElasticNetCV` с более широкой сеткой;
  - убедиться в стандартизации признаков (StandardScaler).
- Проблемы с памятью/временем при RandomForest: уменьшите `n_estimators` в `src/models/train_models.py` для быстрой отладки.

10. Воспроизводимость (reproducibility)

Чтобы повысить воспроизводимость:

- Фиксируйте seed (в проекте используется `random_state=42` для ключевых моделей).
- Укажите версии ключевых библиотек в `requirements.lock.txt`.
- Для полного воспроизведения окружения можно экспортировать `conda env` в `environment.yml`:

```bash
conda env export --name mephi_ml --file environment.yml
```

11. Рекомендуемые проверки для преподавателя

1. Склонировать репозиторий на пустую машину.
2. Создать conda-окружение по инструкции.
3. Поместить исходный файл данных и указать `DATA_PATH` в `.env`.
4. Запустить `make check-config` — убедиться, что всё OK.
5. Запустить `make all` и дождаться успешного окончания.
6. Открыть `models/model_results.json` и `reports/regression_comparison.md` — сравнить с результатами автора.

12. Контакты и отладочная информация

Если во время воспроизведения возникают ошибки, приложите:

- вывод `logs/pipeline.log` (первые 200 строк и последние 200 строк)
- `models/model_results.json`
- содержимое `.env` (скрывая секреты, если есть)

и пришлите их автору проекта для быстрого разбора.

---

Эта инструкция рассчитана на преподавателей и ревьюеров, которым нужно быстро и надёжно воспроизвести пайплайны проекта. Если хотите, могу дополнить инструкцию разделом с конкретными командами для запуска тестового мини-режима (например, train на 50 сэмплах) для быстрой проверки среды.

## Тестовый мини-режим (быстрая проверка среды)

Ниже приведены конкретные команды для быстрого прогонки «микро»-режима: создадим маленькую выборку из обработанных данных (50 сэмплов), укажем её как `DATA_PATH` и запустим обучение. Это полезно для проверки корректности окружения и быстрого детектирования ошибок.

1) Создать небольшую выборку (50 записей) из уже обработанного CSV (если `data/processed_data.csv` есть):

```bash
# создать каталог для временных данных
mkdir -p data/tmp

# создать sample_50.csv из processed_data.csv (сэмплируем случайно 50 строк)
python - <<'PY'
import pandas as pd
df = pd.read_csv('data/processed_data.csv')
df.sample(n=50, random_state=42).to_csv('data/tmp/sample_50.csv', index=False)
print('Saved data/tmp/sample_50.csv (50 rows)')
PY
```

2) Указать `DATA_PATH` на эту выборку и запустить обучение (train) только:

```bash
export DATA_PATH=$(pwd)/data/tmp/sample_50.csv
make train
```

3) Альтернатива: запуск напрямую Python-скрипта (без Makefile), полезно при отладке:

```bash
export DATA_PATH=$(pwd)/data/tmp/sample_50.csv
conda run -n mephi_ml python src/main.py
```

4) Проверить результаты (будут сохраняться в `models/` и `reports/`):

```bash
ls -l models/
jq . models/model_results.json
```

Заметки:
- Для очень быстрой Smoke-проверки можно уменьшить `n_estimators` в RandomForest внутри `src/models/train_models.py` или временно исключить RF из списка моделей.
- Если вы хотите прогонять мини-режим многократно, очищайте `models/` и `reports/` между запусками или используйте временные директории.

## Информация об ОС и аппаратной конфигурации

Автор проводил разработку и обучение на Manjaro Linux. Обучение моделей выполнялось как на CPU, так и на GPU AMD с использованием ROCm (если доступно). Если вы планируете запускать на AMD GPU, убедитесь, что ROCm корректно установлен и conda-окружение содержит совместимые версии PyTorch/пакетов (если вы используете GPU-ускорение в отдельных экспериментах).

Короткие рекомендации для ROCm:
- Убедитесь, что ваша версия ядра и драйверов поддерживается ROCm (см. документацию ROCm).
- Установите ROCm и совместимые пакеты согласно руководству ROCm для вашей дистрибуции (Manjaro — проверить совместимость, на некоторых дистрибутивах требуется дополнительная настройка).
- Если используется PyTorch/пакеты, проверьте их сборки для ROCm; проект по умолчанию работает на CPU и не требует ROCm для стандартного pipeline.
