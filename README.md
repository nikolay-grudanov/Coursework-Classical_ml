# Курсовой проект: Классические ML-методы для предсказания эффективности препаратов

Проект предсказывает эффективность химических соединений (набор показателей IC50, CC50, SI) с помощью классических методов машинного обучения.

## Структура проекта

```
.
├── analysis/          # Результаты разведочного анализа данных (EDA)
├── configs/           # Конфигурационные файлы
├── data/              # Данные
│   ├── processed/     # Обработанные данные для моделирования
│   └── raw/           # Сырые исходные файлы
├── experiments/       # Логи экспериментов / трекинг
├── figures/           # Построенные графики и фигуры
├── logs/              # Логи выполнения
├── models/            # Обученные модели и артефакты
├── notebooks/         # Jupyter-ноутбуки для исследования
├── reports/           # Сгенерированные отчёты
├── src/               # Исходный код
│   ├── data/          # Скрипты обработки данных
│   ├── eval/          # Скрипты оценки моделей
│   ├── features/      # Функции/скрипты для feature engineering
│   ├── models/        # Обучение моделей
│   └── utils/         # Утилиты
├── scripts/           # Вспомогательные скрипты (активация env, проверки)
├── .github/           # CI/CD (GitHub Actions)
├── .pre-commit-config.yaml  # Настройка pre-commit хуков
├── .env.example       # Пример .env-файла для локальной конфигурации
├── Makefile           # Автоматизация задач (читает .env, если он есть)
├── requirements.lock.txt    # Замороженный список зависимостей (только для справки)
└── requirements.txt   # Базовые зависимости
```

## Данные

Набор содержит ~1000 соединений с численными показателями свойств молекул и целевыми метриками:

- IC50: концентрация, при которой достигается половинное ингибирование (меньше — лучше)
- CC50: концентрация цитотоксичности (больше — лучше)
- SI: Selectivity Index = CC50 / IC50 (больше — лучше)

## Задачи

1. Регрессия для IC50
2. Регрессия для CC50
3. Регрессия для SI
4. Классификация: IC50 > медиана
5. Классификация: CC50 > медиана
6. Классификация: SI > медиана
7. Классификация: SI > 8

## Конфигурация окружения и DATA_PATH

Проект рассчитан на conda-окружение. Вместо жёсткой записи пути в коде используйте `.env` в корне репозитория или задайте переменную окружения `DATA_PATH` перед запуском.

Скопируйте пример и отредактируйте:

```bash
cp .env.example .env
```

Поддерживаемые переменные в `.env` (выберите подходящие для вашей системы):

- CONDA_PREFIX — полный путь к conda-окружению, например `/home/user/miniconda3/envs/ml`
- CONDA_ENV_NAME — имя окружения (альтернатива), например `ml`
- CONDA_BIN — путь к каталогу с бинарниками conda (необязательно)
- DATA_PATH — (опционально) переопределение пути к каталогу/файлу с данными, например `/mnt/data/project/data`

Если `DATA_PATH` задан в `.env` или экспортирован в окружении, скрипты и Makefile будут использовать его при загрузке данных. Это удобно для разных машин/CI:

```bash
# пример: экспорт перед запуском
export DATA_PATH=/mnt/data/project/data/data.xlsx
make all
```

Важно: стандартный конфиг в `configs/` использует шаблон вида `${DATA_PATH:-data/data.xlsx}` — это означает: возьми `DATA_PATH`, если задан, иначе используй `data/data.xlsx`.

## Используемый scaler и гиперпараметры ElasticNet (фикс)

В коде для регрессионных моделей используется StandardScaler (нулевое среднее, единичная дисперсия) — это повышает стабильность координатного спуска в ElasticNet/Ridge.

Текущие гиперпараметры ElasticNet (применяются в GridSearchCV):

- alpha (grid): [1e-2, 1e-1, 1.0, 10.0]
- l1_ratio: [0.1, 0.5, 0.9]
- max_iter: 50000
- tol: 1e-4

Эти настройки были выбраны для улучшения сходимости алгоритма и снижения предупреждений о несходимости (ConvergenceWarning).

## Установка и запуск

1. Настройте `.env` (см. выше)
2. Активируйте conda-окружение (рекомендуется использовать `scripts/activate_env.sh`, если он у вас есть):

```bash
source scripts/activate_env.sh
# или вручную
conda activate /path/to/conda_prefix_or_name
```

3. Установите зависимости (если нужно):

```bash
make install
```

4. Запустите полный pipeline:

```bash
make all
```

Или выполните шаги по отдельности:

```bash
make data
make features
make train
make evaluate
make report
```

## Блокировка зависимостей

Полный список зависимостей доступен в `requirements.lock.txt` (только для чтения, для воспроизводимости). Для установки используйте `requirements.txt`.

## Pre-commit хуки

Проект использует pre-commit для качества кода (ruff, black, isort, nbstripout). Установка:

```bash
pre-commit install
```

## Трекинг экспериментов

Эксперименты логируются в `experiments/registry.jsonl`.

## Документация и отчёты

- `reports/eda_report.md` — EDA и предобработка
- `reports/final_report.md` — Финальные выводы и рекомендации

## Выходные артефакты

- Обработанные данные: `data/processed/` (или путь из `DATA_PATH`)
- Обученные модели: `models/`
- Результаты оценки: `reports/`
- Графики: `figures/`
- Логи: `logs/`

Все шаги рекомендуется запускать через `Makefile`, чтобы обеспечить единообразие окружения.


